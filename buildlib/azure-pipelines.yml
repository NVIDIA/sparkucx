# See https://aka.ms/yaml

trigger:
  - master
  - v*.*.x
pr:
  - master
  - v*.*.x

stages:
  - stage: Build
    jobs:
      - job: build
        strategy:
          maxParallel: 1
          matrix:
            spark-2.4:
              profile_version: "2.4"
              spark_version: "2.4.5"
            spark-3.0:
              profile_version: "3.0"
              spark_version: "3.0.1"
        pool:
          name: MLNX
          demands: Maven
        steps:
          - checkout: self
            fetchDepth: 100
            clean: true
            displayName: Checkout
          - bash: |
              set -xeE
              module load dev/mvn dev/jdk
              mvn -B  -Dmaven.repo.local=$(System.DefaultWorkingDirectory)/target/.deps -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn -Pspark-$(profile_version) package
          - bash: |
              set -xeE
              module load tools/spark-$(spark_version) hpcx-gcc
              ls -al $(System.DefaultWorkingDirectory)/target/spark-ucx-1.0-for-spark-$(profile_version)-jar-with-dependencies.jar
              source buildlib/test.sh

              if [[ $(get_rdma_device_iface) != "" ]]
              then
                export SPARK_UCX_JAR=$(System.DefaultWorkingDirectory)/target/spark-ucx-1.0-for-spark-$(profile_version)-jar-with-dependencies.jar
                export SPARK_LOCAL_DIRS=$(System.DefaultWorkingDirectory)/target/spark
                export SPARK_VERSION=$(spark_version)
                export UCX_LIB=$HPCX_UCX_DIR/lib
                cd $(System.DefaultWorkingDirectory)/target/
                run_tests
              else
                echo ##vso[task.complete result=Skipped;]No IB devices found
              fi
            displayName: Run spark tests
